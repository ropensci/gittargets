---
title: "Tutorial: Git data backend"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Tutorial: Git data backend}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
library(gert)
library(gittargets)
library(targets)
tmp <- tempfile()
dir.create(tmp)
knitr::opts_knit$set(root.dir = tmp)
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = identical(Sys.getenv("NOT_CRAN"), "true") &&
    tar_git_ok(verbose = FALSE)
)
```

This tutorial shows how to use `gittargets` with the Git-based data versioning backend. Before proceeding, please read the [README](https://github.com/wlandau/gittargets/blob/main/README.md) file or [documentation website front page](https://wlandau.github.io/gittargets/) for an overview of the package and the workflow diagram for data analysis projects.

![](./workflow.png)

## Installation

Please begin with the installation instructions on the [documentation website](https://wlandau.github.io/gittargets/). In addition, if your `targets` pipeline generates large data files, consider installing [`git-lfs`](https://git-lfs.github.com). The Git data backend in `gittargets` automatically opts into [`git-lfs`](https://git-lfs.github.com), so you should not need to do any manual configuration to reap the performance benefits.

## Write code

To begin development, we write `_targets.R` file for a [`targets`](https://docs.ropensci.org/targets/) pipeline. [`targets`](https://docs.ropensci.org/targets/) can handle large complex pipelines for [machine learning](https://github.com/wlandau/targets-keras), [Bayesian data analysis](http://github.com/wlandau/rmedicine2021-pipeline), and much more. However, this tutorial focuses on a much simpler pipeline for the sake of pedagogical simplicity.

```{r, eval = FALSE}
# _targets.R
library(targets)
list(
  tar_target(data, datasets::airquality),
  tar_target(result, summary(data))
)
```

```{r, echo = FALSE}
tar_script(
  list(
    tar_target(data, datasets::airquality),
    tar_target(result, summary(data))
  )
)
```

## Run pipeline

With our target script in hand, we run the pipeline.^[<http://books.ropensci.org/targets/hpc.html> describes heavy-duty alternatives to `tar_make()`.]

```{r}
tar_make()
```

We inspect the output with `tar_read()`.

```{r}
tar_read(result)
```

## Commit code

We usually iterate between writing code and running the pipeline until we have a decent set of results. After that, we commit the code to a [Git](https://git-scm.com/docs/git-pack-refs) repository, which may or may not live on [GitHub](https://github.com).^[Alternatives to GitHub include GitLab and Bitbucket.] [Happy Git with R](https://happygitwithr.com) is a great way to learn Git, and the [`gert`](https://docs.ropensci.org/gert/) package is a convenient way to interact with Git from R.

```{r, message = FALSE, output = FALSE, results = "hide"}
library(gert)
git_init()
git_add("_targets.R")
git_commit("Begin analyzing the airquality dataset")
git_branch_create("airquality")
```

## Snapshot data

Before we snapshot the data, we should check that the code is up to date in the Git repository and the targets are up to date in the pipeline. The `tar_git_status()` function is an easy way to do this.^[Helper functions `tar_git_status_code()`, `tar_git_status_targets()`, and `tar_git_status_data()` each generate a piece of the `tar_git_status()` output.]

```{r}
tar_git_status()
```

Our code and pipeline look ready for a data snapshot. First, we initialize the data repository with `tar_git_init()`. `tar_git_init()` writes a `.gitattributes` file in the data store that automatically opts into [`git-lfs`](https://git-lfs.github.com). If you have [`git-lfs`](https://git-lfs.github.com) but do not wish to use it, please remove the `.gitattributes` after calling `tar_git_init()`.

```{r}
tar_git_init()
```

Then, we create our first data commit with `tar_git_snapshot()`.^[Ordinarily, `tar_git_snapshot()` shows runs `tar_git_status()` and prompts the user to confirm the snapshot. But in this example, we skip this step.]

```{r, eval = FALSE}
tar_git_snapshot()
```

```{r, echo = FALSE}
tar_git_snapshot(status = FALSE)
```

Each data snapshot is a Git commit and a one-time Git branch. The branch associates the data commit with the code commit that was checked out when the snapshot was created.

## Repeat

Development typically happens in cycles: develop the code, run the pipeline, commit the code, snapshot the data, and repeat. Not all code commits need a data snapshot, especially if the [`targets`](https://docs.ropensci.org/targets/) pipeline generates a lot of data. But even then, it is helpful to snapshot the data at key milestones, e.g. if an alternative research question comes up and it is desirable to create a new Git branch for the code. For example, suppose we wish to apply the same pipeline to a different dataset. The code changes:

```{r, eval = FALSE}
# _targets.R
library(targets)
list(
  tar_target(data, datasets::UKgas), # different dataset
  tar_target(result, summary(data))
)
```

```{r, echo = FALSE}
tar_script(
  list(
    tar_target(data, datasets::UKgas),
    tar_target(result, summary(data))
  )
)
```

We run the pipeline and inspect the new output.

```{r}
tar_make()
```

```{r}
tar_read(result)
```

We put the code in a new Git branch.

```{r}
git_branch_create("UKgas")
git_add("_targets.R")
git_commit("Switch to UKgas dataset")
```

Finally, we create a data snapshot for the new code commit.

```{r, eval = FALSE}
tar_git_snapshot()
```

```{r, echo = FALSE}
tar_git_snapshot(status = FALSE)
```

## View log

Now, suppose we want to switch the project back to the original dataset (`airquality`). To transition completely, we need to revert both the code and the data. If we only revert the code, then the data store will sill reflect the `UKgas` dataset, and none of our targets will be up to date. At this point, it is a good time to pause and check the `gittargets` log to see which code commits have available data snapshots.^[If you chose not to call `tar_git_snapshot()` for some code commits, then not all your code commits will have available data snapshots.]

```{r}
tar_git_log()
```

## Check out code

To check out the old `airquality` code, we use `gert::git_branch_checkout()`.

```{r, message = FALSE, output = FALSE, results = "hide"}
git_branch_checkout("airquality")
```

But because we did not revert the data, our results still reflect the `UKgas` dataset.

```{r}
tar_read(result)
```

Thus, all our targets are out of date.

```{r}
tar_outdated()
```

## Check out data

To bring our targets back up to date with the `airquality` data, instead of beginning a potentially long computation with `tar_make()`, we can check out the data snapshot that matches our current code commit.

```{r}
tar_git_checkout()
```

Now, our results reflect the `airquality` dataset we previously analyzed.

```{r}
tar_read(result)
```

And all our targets are up to date.

```{r}
tar_outdated()
```

## Performance

If your `targets` pipeline generates large data files, consider installing [`git-lfs`](https://git-lfs.github.com). Once you install [`git-lfs`](https://git-lfs.github.com), it should just work on your project right out of the box because `tar_git_init()` writes the following to `_targets/.gitattributes`:

```{sh, eval = FALSE}
objects filter=lfs diff=lfs merge=lfs -text
```

In addition, every data snapshot with `tar_git_snapshot()` creates a new Git branch. With thousands of commits and thus thousands of branches, performance may suffer. If you notice slowness, run [`git pack-refs --all`](https://git-scm.com/docs/git-pack-refs) on the [`targets` data store](https://books.ropensci.org/targets/files.html#internal-data-files) repository.
